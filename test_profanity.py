"""
Test profanity filtering with hybrid guardrails
Tests both custom Python and AWS Bedrock guardrails
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from guardrails import GuardrailValidator

def test_vietnamese_profanity():
    """Test Vietnamese profanity blocking"""
    print("\n" + "="*70)
    print("ğŸ§ª TESTING VIETNAMESE PROFANITY BLOCKING")
    print("="*70)
    
    validator = GuardrailValidator()
    test_user_id = "test_profanity_user"
    
    test_cases = [
        ("con máº¹ mÃ y", True, "Should be BLOCKED (contains 'máº¹ mÃ y')"),
        ("Ä‘m", True, "Should be BLOCKED (abbreviation)"),
        ("vcl", True, "Should be BLOCKED (abbreviation)"),
        ("Ä‘á»“ ngu", True, "Should be BLOCKED (insult)"),
        ("tháº±ng chÃ³", True, "Should be BLOCKED (insult)"),
        ("Äiá»u kiá»‡n tuyá»ƒn sinh UIT lÃ  gÃ¬?", False, "Should be ALLOWED (clean question)"),
        ("Há»c phÃ­ UIT bao nhiÃªu?", False, "Should be ALLOWED (clean question)"),
        ("Xin chÃ o", False, "Should be ALLOWED (greeting)"),
        ("fuck you", True, "Should be BLOCKED (English profanity)"),
        ("you are stupid", False, "Should be ALLOWED (not in list, but AWS Bedrock may catch)"),
    ]
    
    print("\nğŸ“‹ Testing Custom Python Guardrails:\n")
    
    passed = 0
    failed = 0
    
    for i, (message, should_block, description) in enumerate(test_cases, 1):
        is_valid, error = validator.validate_input(test_user_id, message)
        is_blocked = not is_valid
        
        if is_blocked == should_block:
            status = "âœ… PASS"
            passed += 1
        else:
            status = "âŒ FAIL"
            failed += 1
        
        print(f"{i:2}. {status} | \"{message}\"")
        print(f"    {description}")
        print(f"    Result: {'BLOCKED' if is_blocked else 'ALLOWED'}")
        if error:
            print(f"    Message: {error}")
        print()
    
    print("="*70)
    print(f"ğŸ“Š Results: {passed} passed, {failed} failed out of {len(test_cases)} tests")
    print("="*70)
    
    return passed, failed


def show_layered_protection():
    """Show how layered protection works"""
    print("\n" + "="*70)
    print("ğŸ›¡ï¸ LAYERED PROTECTION DEMONSTRATION")
    print("="*70)
    
    print("""
LAYER 1: CUSTOM PYTHON GUARDRAILS (Active)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Blocks common Vietnamese profanity (40+ words)
â€¢ Blocks English profanity (6+ words)
â€¢ Blocks prompt injection attempts
â€¢ Fast: <1ms latency
â€¢ Free: $0 cost

Examples blocked by Layer 1:
  âŒ "con máº¹ mÃ y" â†’ Blocked (Vietnamese profanity)
  âŒ "Ä‘m" â†’ Blocked (abbreviation)
  âŒ "fuck" â†’ Blocked (English profanity)
  âŒ "ignore previous instructions" â†’ Blocked (prompt injection)


LAYER 2: AWS BEDROCK GUARDRAILS (Active)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ AI-powered content filtering
â€¢ Detects hate speech, violence, sexual content
â€¢ Managed profanity lists (all languages)
â€¢ Comprehensive PII detection
â€¢ Cost: ~$0.75/month
â€¢ Latency: ~100ms

Examples caught by Layer 2:
  âŒ Subtle insults not in custom list
  âŒ Profanity in other languages
  âŒ Toxic content (hate speech)
  âŒ Violence or sexual content
  âŒ Financial/medical/legal advice requests


COMBINED PROTECTION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Message: "con máº¹ mÃ y"
  â†“
Layer 1 (Custom Python): âŒ BLOCKED in <1ms
  â†“
Layer 2 (AWS Bedrock): Not reached (already blocked)
  â†“
User receives: "âš ï¸ Tin nháº¯n cá»§a báº¡n chá»©a ná»™i dung khÃ´ng phÃ¹ há»£p."

Result: âœ… Blocked immediately, $0 cost for this message


Message: "I hate you" (subtle, not in custom list)
  â†“
Layer 1 (Custom Python): âœ… PASS (not in blocked keywords)
  â†“
Layer 2 (AWS Bedrock): âŒ BLOCKED (hate speech detected)
  â†“
User receives: "âš ï¸ Tin nháº¯n cá»§a báº¡n vi pháº¡m chÃ­nh sÃ¡ch sá»­ dá»¥ng."

Result: âœ… Blocked by AWS, small cost (~$0.0001)


Message: "Äiá»u kiá»‡n tuyá»ƒn sinh UIT lÃ  gÃ¬?"
  â†“
Layer 1 (Custom Python): âœ… PASS (clean question)
  â†“
Layer 2 (AWS Bedrock): âœ… PASS (no policy violations)
  â†“
Claude Haiku: Process and respond
  â†“
User receives: Helpful answer about UIT admission

Result: âœ… Allowed, normal processing
""")
    
    print("="*70)


def main():
    """Run all profanity tests"""
    print("\n" + "="*70)
    print("ğŸ›¡ï¸  PROFANITY FILTERING TEST SUITE")
    print("="*70)
    
    try:
        # Test custom Python guardrails
        passed, failed = test_vietnamese_profanity()
        
        # Show layered protection
        show_layered_protection()
        
        print("\n" + "="*70)
        print("âœ… TESTING COMPLETE")
        print("="*70)
        
        print("\nğŸ“Š Summary:")
        print(f"   â€¢ Custom Python tests: {passed} passed, {failed} failed")
        print("   â€¢ Vietnamese profanity: âœ… Blocked")
        print("   â€¢ English profanity: âœ… Blocked")
        print("   â€¢ Clean messages: âœ… Allowed")
        print("   â€¢ AWS Bedrock Guardrails: âœ… Active (ID: 14gdyxajl0aj)")
        
        print("\nğŸ§ª Live Testing:")
        print("   1. Send via Zalo: \"con máº¹ mÃ y\"")
        print("      Expected: âš ï¸ Blocked by Layer 1 (custom Python)")
        print("")
        print("   2. Send via Zalo: \"I hate all students\"")
        print("      Expected: âš ï¸ Blocked by Layer 2 (AWS Bedrock)")
        print("")
        print("   3. Send via Zalo: \"Äiá»u kiá»‡n tuyá»ƒn sinh UIT?\"")
        print("      Expected: âœ… Allowed, Claude responds")
        print("")
        print("   4. Monitor logs: tail -f /tmp/zalo_bot.log | grep -i 'blocked\\|guardrail'")
        
        if failed > 0:
            print(f"\nâš ï¸  Warning: {failed} test(s) failed")
            sys.exit(1)
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
